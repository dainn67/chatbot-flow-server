# Chatbot Flow Server

Server API cho quáº£n lÃ½ chatbot flows vá»›i tÃ­ch há»£p LLM (OpenAI, Gemini).

## ğŸš€ Khá»Ÿi Ä‘á»™ng nhanh

### 1. CÃ i Ä‘áº·t dependencies

```bash
# Táº¡o virtual environment (náº¿u chÆ°a cÃ³)
python -m venv venv

# KÃ­ch hoáº¡t virtual environment
# macOS/Linux:
source venv/bin/activate
# Windows:
# venv\Scripts\activate

# CÃ i Ä‘áº·t packages
pip install -r requirements.txt
```

### 2. Cáº¥u hÃ¬nh mÃ´i trÆ°á»ng

Táº¡o file `.env` trong thÆ° má»¥c gá»‘c:

```env
OPENAI_API_KEY=your_openai_api_key_here
GEMINI_API_KEY=your_gemini_api_key_here
```

### 3. Cháº¡y server

```bash
# Development mode vá»›i auto-reload
uvicorn app.main:app --reload

# Hoáº·c cháº¡y trá»±c tiáº¿p
python -m app.main
```

Server sáº½ cháº¡y táº¡i: http://localhost:8000

## ğŸ“š API Documentation

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## ğŸ—ï¸ Cáº¥u trÃºc dá»± Ã¡n

```
chatbot-flow-server/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py           # Package initialization
â”‚   â”œâ”€â”€ main.py               # FastAPI app entry point
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ config.py         # Configuration settings
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ llm_service.py    # LLM service interface
â”‚   â”‚   â”œâ”€â”€ openai_service.py # OpenAI integration
â”‚   â”‚   â””â”€â”€ gemini_service.py # Gemini integration
â”‚   â””â”€â”€ flows/
â”‚       â””â”€â”€ question_chatbot.py # Chatbot flow logic
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ .env                      # Environment variables (táº¡o thá»§ cÃ´ng)
â””â”€â”€ README.md
```

## ğŸ”§ API Endpoints

### Health Check

- `GET /` - Root health check
- `GET /health` - Detailed health status

## ğŸ“ Ghi chÃº

- Äáº£m báº£o Ä‘Ã£ cáº¥u hÃ¬nh API keys trong file `.env`
- Server cháº¡y á»Ÿ port 8000 theo máº·c Ä‘á»‹nh
- CORS Ä‘Æ°á»£c cáº¥u hÃ¬nh Ä‘á»ƒ cháº¥p nháº­n táº¥t cáº£ origins (nÃªn giá»›i háº¡n trong production)
