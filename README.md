# Chatbot Flow Server

Server API cho quáº£n lÃ½ chatbot flows vá»›i tÃ­ch há»£p LLM (OpenAI, Google Gemini).

## âœ¨ TÃ­nh nÄƒng

- ğŸ¤– TÃ­ch há»£p nhiá»u LLM providers (OpenAI GPT, Google Gemini)
- âš¡ Async/await support cho performance tá»‘t
- ğŸ”„ Thread pool executor cho Gemini API
- ğŸ“ API documentation tá»± Ä‘á»™ng vá»›i Swagger UI
- ğŸ”’ Environment-based configuration
- ğŸŒ CORS support

## ğŸš€ Khá»Ÿi Ä‘á»™ng nhanh

### 1. CÃ i Ä‘áº·t dependencies

```bash
# Táº¡o virtual environment (náº¿u chÆ°a cÃ³)
python -m venv venv

# KÃ­ch hoáº¡t virtual environment
# macOS/Linux:
source venv/bin/activate
# Windows:
# venv\Scripts\activate

# CÃ i Ä‘áº·t packages
pip install -r requirements.txt
```

### 2. Cáº¥u hÃ¬nh mÃ´i trÆ°á»ng

Táº¡o file `.env` trong thÆ° má»¥c gá»‘c:

```env
OPENAI_API_KEY=your_openai_api_key_here
GEMINI_API_KEY=your_gemini_api_key_here
```

### 3. Cháº¡y server

```bash
# Development mode vá»›i auto-reload
uvicorn app.main:app --reload

# Hoáº·c cháº¡y trá»±c tiáº¿p
python -m app.main
```

Server sáº½ cháº¡y táº¡i: http://localhost:8000

## ğŸ“š API Documentation

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## ğŸ—ï¸ Cáº¥u trÃºc dá»± Ã¡n

```
chatbot-flow-server/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py           # Package initialization
â”‚   â”œâ”€â”€ main.py               # FastAPI app entry point
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ config.py         # Configuration settings
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ flow.py           # Flow API routes
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ llm_service.py    # LLM service interface
â”‚   â”‚   â”œâ”€â”€ openai_service.py # OpenAI GPT integration
â”‚   â”‚   â””â”€â”€ gemini_service.py # Google Gemini integration
â”‚   â””â”€â”€ flows/
â”‚       â””â”€â”€ question_chatbot.py # Chatbot flow logic
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ .env                      # Environment variables (táº¡o thá»§ cÃ´ng)
â””â”€â”€ README.md
```

## ğŸ”§ API Endpoints

### Health Check

- **GET** `/` - Root health check
- **GET** `/health` - Detailed health status (kiá»ƒm tra cáº¥u hÃ¬nh API keys)

### Chatbot Flows

- **POST** `/api/flows/ask` - Gá»­i cÃ¢u há»i Ä‘áº¿n chatbot

**Request body:**
```json
{
  "user_input": "Xin chÃ o, báº¡n cÃ³ khá»e khÃ´ng?"
}
```

**Response:**
```json
{
  "user_input": "Xin chÃ o, báº¡n cÃ³ khá»e khÃ´ng?",
  "llm_response": "CÃ¢u tráº£ lá»i tá»« LLM..."
}
```

## ğŸ› ï¸ Tech Stack

- **Framework**: FastAPI 0.104.1
- **Server**: Uvicorn
- **LLM Integrations**:
  - OpenAI API 1.3.0
  - Google Generative AI 0.8.5
- **Python**: 3.8+

## ğŸ“ Ghi chÃº

- Äáº£m báº£o Ä‘Ã£ cáº¥u hÃ¬nh API keys trong file `.env`
- Server cháº¡y á»Ÿ port 8000 theo máº·c Ä‘á»‹nh
- CORS Ä‘Æ°á»£c cáº¥u hÃ¬nh Ä‘á»ƒ cháº¥p nháº­n táº¥t cáº£ origins (nÃªn giá»›i háº¡n trong production)
- Gemini API sá»­ dá»¥ng thread pool executor Ä‘á»ƒ xá»­ lÃ½ async calls
- Máº·c Ä‘á»‹nh sá»­ dá»¥ng model `gemini-2.0-flash-exp`

## ğŸ› Troubleshooting

### Import error "google.generativeai could not be resolved"

1. Äáº£m báº£o Ä‘Ã£ cÃ i Ä‘áº·t dependencies: `pip install -r requirements.txt`
2. Kiá»ƒm tra Ä‘Ã£ activate virtual environment
3. Khá»Ÿi Ä‘á»™ng láº¡i IDE Ä‘á»ƒ nháº­n diá»‡n láº¡i Python interpreter
4. Chá»n Ä‘Ãºng Python interpreter: `./venv/bin/python`

### API Key errors

Kiá»ƒm tra file `.env` Ä‘Ã£ Ä‘Æ°á»£c táº¡o vÃ  cÃ³ Ä‘Ãºng API keys. Truy cáº­p `/health` Ä‘á»ƒ xem tráº¡ng thÃ¡i cáº¥u hÃ¬nh.
